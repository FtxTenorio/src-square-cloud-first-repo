/**
 * Nexus AI Engine
 * Main AI module that orchestrates responses
 * Personalidade √© por chat (n√£o por usu√°rio).
 */

import logger from '../utils/logger.js';
import { matchPattern } from './patterns.js';
import * as openai from './providers/openai.js';
import moodEngine from './moodEngine.js';
import * as chatService from '../services/chatService.js';
import * as personalityService from '../services/personalityService.js';
import AppConfig from '../../cmdhub/models/AppConfig.js';
import ServerConfig from '../../cmdhub/models/ServerConfig.js';
import { DM_ROUTINE_TOOLS, executeDmRoutineTool } from './tools/dmRoutineTools.js';
import * as userPreferenceService from '../../events/services/userPreferenceService.js';

const AI_CONFIG_DEFAULTS = { model: 'gpt-4o-mini', maxTokens: 500, temperature: 0.8 };

/**
 * Carrega config de OpenAI: por guild (ServerConfig) sobrescreve global (AppConfig).
 * @param {string|null} guildId - Guild do canal; se null usa s√≥ AppConfig.
 * @returns {Promise<{ model, maxTokens, temperature }>}
 */
async function getOpenAIConfig(guildId) {
    const out = { ...AI_CONFIG_DEFAULTS };
    let app = await AppConfig.findOne({ _id: 'app' }).lean();
    if (app) {
        if (app.aiModel) out.model = app.aiModel;
        if (app.aiMaxTokens != null) out.maxTokens = app.aiMaxTokens;
        if (app.aiTemperature != null) out.temperature = app.aiTemperature;
    }
    if (guildId) {
        const server = await ServerConfig.findOne({ guildId }).lean();
        if (server) {
            if (server.aiModel != null && server.aiModel !== '') out.model = server.aiModel;
            if (server.aiMaxTokens != null) out.maxTokens = server.aiMaxTokens;
            if (server.aiTemperature != null) out.temperature = server.aiTemperature;
        }
    }
    return out;
}

// Conversation context storage
const conversationContext = new Map();

/**
 * Track conversation context
 */
function updateContext(userId, channelId, message) {
    const key = `${userId}-${channelId}`;
    let context = conversationContext.get(key) || { 
        messageCount: 0, 
        topics: [],
        lastTimestamp: null 
    };
    
    context.messageCount++;
    context.lastMessage = message;
    context.lastTimestamp = Date.now();
    
    conversationContext.set(key, context);
    
    return { addNote: false };
}

/**
 * Clear user context
 */
export function clearContext(userId, channelId) {
    const key = `${userId}-${channelId}`;
    conversationContext.delete(key);
}

/**
 * Main response generator
 * Orquestra personalidade do chat e provedores de IA (sem mood autom√°tico nem pattern matching).
 * Returns { content }.
 */
export async function generateResponse(message, history = [], options = {}) {
    const userId = message.author?.id || message.userId || 'unknown';
    const channelId = message.channel?.id || message.channelId || 'unknown';
    const guildId = message.guild?.id || message.guildId || null;
    const content = (message.content || '').trim();
    const contentLower = content.toLowerCase();
    
    // Personalidade do chat (sem mood autom√°tico)
    const chatPersonality = await chatService.getChatPersonality(channelId, guildId || 'DM');
    let personality = await personalityService.getForAI(chatPersonality?.slug || 'friendly');

    // For√ßar modo analista em DMs, independentemente da personalidade do canal
    const isDM = guildId == null;
    if (isDM) {
        personality = await personalityService.getForAI('analista');
    }

    // Update context
    updateContext(userId, channelId, content);
    
    // 2. Try OpenAI if configured (model/tokens/temperature v√™m de AppConfig + ServerConfig por guildId)
    if (openai.isConfigured()) {
        try {
            let aiConfig = await getOpenAIConfig(guildId);

            // Overrides por usu√°rio em DM (admin.dm* nas prefer√™ncias)
            if (isDM) {
                try {
                    const prefs = await userPreferenceService.getPreferences(userId);
                    const admin = prefs?.admin || {};
                    if (admin.dmModel) aiConfig.model = admin.dmModel;
                    if (admin.dmMaxTokens != null) aiConfig.maxTokens = admin.dmMaxTokens;
                    if (admin.dmTemperature != null) aiConfig.temperature = admin.dmTemperature;
                } catch (e) {
                    logger.warn('AI', `Erro ao carregar prefs admin.dm* para ${userId}: ${e.message}`);
                }
            }

            const baseOptions = {
                currentUsername: message.author?.username,
                model: aiConfig.model,
                maxTokens: aiConfig.maxTokens,
                temperature: aiConfig.temperature
            };

            // DM: habilitar fun√ß√µes (tools) para a IA ler e editar rotinas do usu√°rio
            if (isDM) {
                const result = await openai.generateResponseWithTools(content, personality, history, {
                    ...baseOptions,
                    userId,
                    tools: DM_ROUTINE_TOOLS,
                    executeTool: executeDmRoutineTool,
                    messageContext: { message: options.discordMessage, saveToolInfo: options.saveToolInfo }
                });
                return { content: result.content };
            }

            const result = await openai.generateResponse(content, personality, history, baseOptions);
            return { content: result.content };
        } catch (error) {
            logger.ai.error(error);
            return { content: getSleepingMessage() };
        }
    }
    
    // 3. Fallback - Frieren est√° dormindo
    return { content: getSleepingMessage() };
}

/**
 * Get current mood for a channel
 */
export async function getChannelMood(channelId) {
    return await moodEngine.getCurrentMood(channelId);
}

/**
 * Force set mood for a channel
 */
export async function setChannelMood(channelId, mood, guildId = null) {
    return await moodEngine.setMood(channelId, mood, guildId);
}

/**
 * Get sleeping Frieren message
 */
function getSleepingMessage() {
    const sleepingMessages = [
        'üí§ *Frieren est√° dormindo... Afinal, elfos precisam de descanso tamb√©m (mesmo que seja por alguns s√©culos).*',
        'üò¥ *Frieren adormeceu enquanto meditava. Volte daqui a uns 10 anos, talvez ela acorde.*',
        'üåô *A maga est√° em um sono profundo. Himmel diria para ter paci√™ncia...*',
        'üí§ *Zzz... Frieren est√° tirando uma soneca. Para ela, "uma soneca" pode significar algumas d√©cadas.*',
        'üò™ *Frieren n√£o est√° dispon√≠vel no momento. Ela encontrou um lugar confort√°vel para dormir.*',
        'üßù‚Äç‚ôÄÔ∏èüí§ *"S√≥ vou descansar os olhos por um momento..." - Frieren, h√° 3 dias atr√°s.*',
        'üå∏ *Frieren est√° dormindo sob uma √°rvore de cerejeira. Ela prometeu acordar na pr√≥xima primavera... de qual s√©culo, ela n√£o especificou.*',
        'üìöüí§ *Frieren adormeceu lendo um grim√≥rio. A magia de IA est√° temporariamente indispon√≠vel.*'
    ];
    
    return sleepingMessages[Math.floor(Math.random() * sleepingMessages.length)];
}

/**
 * Lista personalidades dispon√≠veis (para comandos)
 */
export async function getAvailablePersonalities() {
    const list = await personalityService.listAll();
    return list.map(p => ({
        id: p.slug,
        slug: p.slug,
        name: p.name,
        emoji: p.emoji,
        description: p.description
    }));
}

/**
 * Define a personalidade do chat (por canal)
 */
export async function setChatPersonality(channelId, personalityId, guildId = null) {
    return chatService.setPersonality(channelId, personalityId, guildId || 'DM');
}

/**
 * Obt√©m a personalidade atual do chat
 */
export async function getChatPersonality(channelId, guildId = null) {
    return chatService.getChatPersonality(channelId, guildId || 'DM');
}

// Export everything
export default {
    generateResponse,
    getAvailablePersonalities,
    getChannelMood,
    setChannelMood,
    setChatPersonality,
    getChatPersonality,
    clearContext,
    moodEngine
};
